###########################
# Chapter 1 - Introduction
###########################
- where can we find distributed systems
watch a movie on demand
shop online
order a ride share service through our mobile
search for something online

- companies running highly scalable distributed systems to:
handle millions of users
Petabytes of data
provide consistent user experience

- Cloud (AWS, Azure, GCP, etc) is a distributed system designed for companies and software developers


# Evolution of a small software startup company
- example:
John creates an awesome website + mobile app to purchase computer products and share the reviews with friends / users
He creates that website in his laptop and mobile with a webserver computer as the backend webserver / disk
As the user base grows, the computer can't handle and performance degrades
John upgrades his computer - vertical scaling
However, more users still hit the limits of the computer
Also single point of failure - if computer goes down - everything stops
High latency for users who are far away in other countries / continents
Security and Privacy may also be breached easily

- Solution: Distributed System
A Distributed System is a system of several processes, running on different computers,
 communicating with each other through the network,
 and are sharing a state
 or are working together to achieve a common goal

- What is a Process
Any application / jar running in computer's memory

# Inter-process communication (same machine)
- processes communicating to each other via:
File System (hard disk)
Memory

- not a distributed system

# Decoupling of processes
- run each process on different computers
- horizontal scaling - adding more machines
- network communication between machines
- sharing state and working toward a common goal => no common goal - not a distributed system


######################################################################
# Chapter 2 - Cluster Coordination Service and Distributed Algorithms
######################################################################

## Introduction to Cluster Coordination & Theory of Leader Election

# Terminology
- Node
a process running on a dedicated machine
can communicate with each other on a network

- Cluster
collection of computer/nodes connected to each other
the nodes in a cluster are working on the same task and typically are running the same code


# Design our first disributed algorithm
- how to hand a task to a Cluster
- how to break the work among nodes

# Attempt 1 - manual distribution
- define each node a separate task manually
- but thousands of tasks received per second - impossible to manually distribute it

# Attempt 2 - manually elect a leader
- a leader node decides and distributes (programatically) tasks amongs nodes
- but single point of failure if leader node is down

# Attempt 3 - automatic leader election
- algorithm to elect leader and monitor the health
- failure detection -> re-election of new leader
- joining of old leader after recovery

# challenges of leader/master -> workers architecture
- automatic and system leader election is not a trivial task to solve, even among people
- arriving to an agreement on a leader in a large cluster of nodes is even harder
- by default, each node knows only about itself - thus, service registry and discovery is required
- failure detection mechanism is necessary to trigger automatic leader re-election in a cluster

# Master-Workers coordinaton solution
- implement distributed algorithms for consensus and failover from scratch
- Apache Zookeeper - high performance distributed system coordination service


###################
# Apache Zookeeper
###################
- a high performance coordination service designed specifically for distributed systems
- popular technology used by many companies and projects (Kafka, Hadoop, HBase, etc)
- provides an abstraction layer for higher level distributed algorithms

# what makes Zookeeper a good solution?
- is a distributed system itself that provides us high availability and reliability
- typically runs in a cluster of an odd number of nodes, higher than 3
- uses redundancy to allow failures and stay functional

# Zookeeper properties
- Zookeeper's abstraction and data model is very much similar to a file system - root node and directories / subdirectories / files
- each node in a Zookeeper is called Znodes
- Znodes:
hybrid between a file and a directory
Znodes can store any data inside - like a file
Znodes can have children Znodes - like a directory

- two types of Znodes:
persistent: persists between sessions
ephermal: is deleted when the session ends

- An Ephermal Znode is deleted automatically as soon as its creator process disconnects from zookeeper
this can help to detect that a process dies or disconnected from the zookeeper service

- a Persistent Znode stays within Zookeeper until it is explicitly deleted
this can help to store data in between sessions


## Leader election algorithn
Step 1:
- every node connects to Zookeeper and creates its Znode under Zookeeper's Znode = /election
- zookeeper gives a unique number to each new Znode in the order of their addition
Step 2:
- each node will query the children of /election
- it's guaranteed that node will receive all the children Znodes which were created "prior" to its own Znode
Step 3:
- if no children received, then the current node is the first one and becomes the leader
- elected based on lower number priority or some other algorithm
- if not the leader - it will follow the instructions from leader as the leader will already be elected

summary:
Each node in the cluster will try to create a znode with the lowest sequence number available as the znode's name
When a node detects that its znode has the lowest sequence number, it becomes the leader
When a node detects that its znode doesn't have the lowest sequence number, it becomes the follower
Zookeeper guarantees a monotonically increasing, unique sequence number for each node that requests a sequence suffixed znode


## resources
https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/zookeeper-at-twitter
https://zookeeper.apache.org/doc/r3.7.0/index.html


## Zookeeper Server and Client - Download and setup
- Zookeeper configuration and startup
- Zookeeper command line client
- development done locally on a single computer but deploy to production cluster
- Zookeeper client makes Znodes appear like files on our computer
however, there are no Znodes stored in our file system - it's a representation of the zookeeper in-memory data model

- download:
https://zookeeper.apache.org/releases.html
https://www.apache.org/dyn/closer.lua/zookeeper/zookeeper-3.7.0/apache-zookeeper-3.7.0-bin.tar.gz

- configuration:
create a new folder as logs/
rename conf/zoo.cfg
change dataDir to point to logs/

- run:
start server
./bin/zkServer.sh start
./bin/zkServer.sh status

start client
./bin/zkCli.sh

- client command line - can type commands here
help
ls / => total znodes available
create /parent "some parent data" => create parent znode
create /parent/child "some child data" => create child znode
set /parent/child "got new data" => data changed
ls /parent
get /parent => info about parent znode
delete /parent
deleteall /parent
create /election ""


## Zookeeper threading model
- application start code in the main method is executed on the main thread
- when Zookeeper object is created, 2 additional threads are created:
event thread
IO thread

# IO Thread
- handles all the network communication with Zookeeper servers
- handles Zookeeper requests and responses
- responds to pings
- session management
- session timeouts
- etc.

# Event Thread
- manages Zookeeper events
  connection (KeeperState.SyncConnected)
  disconnection (KeeperState.Disconnected)
- custom znode Watchers and Triggers to subscribe to
- Events are executed on Event Thread in order

- demo code: LeaderElection

- when the Zookeeper client connects to Zookeeper server - as its all asynchronous and event driven
server will respond the events in the separate event threads
thus client needs to implement Watcher and use event handlers to handle WatchedEvent in overridden process() method
- for successful connection - server sends event of type None and state as Event.KeeperState.SyncConnected
- server also keeps on sending ping to check if the client is alive and connected
- client maintains a background IO thread that has to send and respond to pings to and from server
- if the server is down after successful connection, the event state will change and then client can close the connection

- to package the code, need maven plugin: maven-assembly-plugin
- then run: mvn clean package
- execute 4 nodes in 4 git bash
java -jar target/leader.election-1.0-SNAPSHOT-jar-with-dependencies.jar


## Watchers and Triggers
- we can register a watcher when we call the methods
getChildren() - get notified when the list of a znode's children changes
getData() - get notified if a znode's data gets modified
exists() - get notified if a znode gets deleted or created

- watcher allows us to get a notifcation when a change happens
- demo code: WatchersDemo


## Leader Re-election
- for reelection of leader, instead of all cluster nodes "watching" the znodes
only the next cluster node watches the previous ephermal znode
if the leader cluster node dies, its znode will send the deleted node event to the next cluster node
and next cluster node will become the new leader

- demo code: LeaderReelection

## Fault Tolerance and Horizontal Scalability are very important properties
- Fault Tolerance: business can run 24X7 with no interruptions
- Horizontal Scalability: can dynamically grow our business on demand


## Auto-healer
- In cloud computing, auto-healing is a feature used to monitor a cluster and detect faulty application instances
- If a faulty instance is detected, the node is shut down and a new node is created with a healthy application instance

java -jar target/autohealer-1.0-SNAPSHOT-jar-with-dependencies.jar 10 "../flakyworker/target/flaky.worker-1.0-SNAPSHOT-jar-with-dependencies.jar"
java -jar .\target\autohealer-1.0-SNAPSHOT-jar-with-dependencies.jar 10 "..\flakyworker\target\flaky.worker-1.0-SNAPSHOT-jar-with-dependencies.jar"
C:\Users\rishi\Downloads\Study\Udemy\Design Patterns\distributed-systems\leader.election\flakyworker\target\flaky.worker-1.0-SNAPSHOT-jar-with-dependencies.jar


##############################################################
# Chapter 3 - Cluster Management, Registration and Discovery
##############################################################

## Service Discovery
- nodes should know which other nodes are present in the cluster
- use dynamic configuration tool like Chef or Puppet to distribute among the nodes
- best to use service registry in Zookeeper
- other techs: etcd, consul, Netflix Eureka, etc...

## Service Registry with Zookeeper
- each node will create an ephermal Znode with its address in it with permanent Znode /service_registry as ephermal Znode's parent
- then any node can call getChildren() on /service_registry to get all ephermal Znodes
- and use getData() method on ephermal Znode to get the address

## pending - demo code


#####################################
# Chapter 4 - Network Communication
#####################################

## Introduction to Network Communication
- TCP/IP Model
- Full example of a request traveling through the network

# Multithreaded vs Distributed systems
- in the same java process, all the threads communicate with each other using same shared memory
- in the distributed systems, communication between nodes is different as there is no shared memory

# TCP/IP Network Model

Machine 1                                           Machine 2
----------                                         -----------
Application <---> HTTP, FTP, SMTP               <--->  Application
Transport   <---> TCP, UDP                      <--->  Transport
Internet    <---> IP, ICMP                      <--->  Internet
Data Link   <---> Ethernet, 802.11, ARP, RAPR   <--->  Data Link

- each layer talks to the same layer on other machine to transfer data


# Layer 1 - Data Link
- Machine 1 <--> Ethernet / Router <--> Machine 2 (within the same LAN network)
- physical delivery of data over a single link
- In charge of:
  encapsulation of the data
  flow control
  error detection and correction
  etc..

- Ethernet protocol
works on MAC addresses
MAC address 1 of first machine -> Link 1 to router's MAC address 2 -> Link 2 to MAC address 3 of the second machine


# Layer 2 - Internet
- works on IP address
- Source IP address -> Router 1 IP address -> Router 2 over internet -> several hops to other routers -> Destination Router IP address -> Destination IP address
- it doesn't know which process on the destination machine to deliver the data
- it's only job is to connect from source machine IP address to destination machine IP address


# Layer 3 - Transport
- delivers the data to actual process running on destination machine
- destination has dedicated PORT where the process is listening (chosen before)
- source port is generated at sending time and it can be random
- OS knows which process to deliver the data to based on PORT
- TCP and UDP are the most common protocol


UDP
- Connectionless
- best effort - unreliable
- messages can be
  lost
  duplicated
  reordered
- based on a unit called Datagram which is limited in size
- preferred when the speed and simplicity is more important than reliability
- use case:
sending debug information to a distributed logging service
real-time data stream service such as video or audio or market data
online gaming
broadcasting


TCP
- reliable - guarantees data delivery as sent, without any losses
- connection between 2 points - formed by source IP + port (unique) + destination IP + listening port
  needs to be created before data is sent
  shut down in the end
- works as a streaming interface
- more popular protocol in distributed systems because of the reliability
- use case:
build a HTTP web server: IP + port 80
now any number of clients can connect using TCP -> each having dedicated channel (TCP socket connection) to the web server

- TCP is based on stream of bytes, however doesn't know which bytes corresponds to which message / command etc
- thus parsing messages / commands from stream of bytes is very hard
- thats why we have final layer - Application layer


# Layer 4 - Application
- several protocols which can help parse the stream of bytes received
- ex:
FTP (File Transport Protocol) - transfering files through the web
SMTP (Simple Mail Transfer Protocol) - sending and receiving mails
DNS (DOmain Name System) - Translating host names into IP addresses
HTTP (Hypertext Transport Protocol) - Transmitting Hypermedia documents, video, sound, images



## Full example of a request traveling through the network
Client <-> Router <-> Server

1. Application layer - client sends a HTTP GET request
GET HTTP/1.1
Host: 24.28.18.17:8080
Content-Length: 20
...

2. Transport layer - adds destination port and source port
Dest Port: 8080
Src Port: 12345

3. Internet layer - adds src and desitnation IP addresses
Dest IP: 24.28.18.17
Src IP: 23.241.168.123 (client's machine IP)

4. Data Link layer - adds src and destination MAC addresses and also Error Connection Data
Dest MAC: 18:FE:93:9A:1C:76
Src MAC: A5:DE:43:AC:11:63 (client's machine MAC)


- the above Frame created by client is send to the router
- router
  removes Ethernet protocol header
  looks at the destination IP address
  looks at the routing table and figures out which n/w it should be sent
  adds a new Ethernet header: with router's MAC address as source MAC address
  sends the Frame to the server

- Server side: the Frame is peeled off for data in the reverse order (data link layer first)

- Service registry: http://27.15.97.15:8081
27.15.97.15 - IP address in Internet layer
8081 - port in Transport layer
http - HTTP protocol in Application layer

- Data packaging and Serilaization is done to send efficiently between the nodes in the cluster



########
# HTTP
########

# HTTP Fundamentals
- used for communication between client and server at Application layer
- HTTP Request Structure has 5 parts:
Method: GET / POST / PUT / DELETE etc
Relative Path: /path
Protocol version: HTTP/1.1
HTTP Headers: Content-Length, Content-Type, etc
Message Body

- HTTP GET
safe - only retrieval action
idempotent - whether use it N times or once will result in same
does NOT contain message body

- HTTP GET use cases
heartbeat - can be used to check health of nodes
distributed data retrieval - meaning can retrieve data from microservices without knowling anything about underlying data base

- HTTP POST
contains message body and expects data returned from server

- Relative path
http://123..../users?userId=123&month=03

/users is relative path
everything after ? is Query String

- Protocol version
HTTP/1.1 or HTTP/2

# HTTP/1.1
creates a dedicated connection between client and server
one 1 request can be sent via this connection, 2nd request has to wait until the first response is received back to the client
if creating new connection for every request - this can be very expensive operation

no of outgoing connections as a client is limited by:
- no of ports
- operating system

# HTTP/2
- breaks the same single connection into multiple streams - thus can contain multiple request / responses in the same connection

# HTTP Headers
- Key value pairs
- Multiple Values for the same key can be separated by ;
- Some headers are used only in requests or responses or both
- can pass custom headers
- allow the recipients to take actions before reading the message body, like
memory allocation
skipping / forwarding (proxying)

- In HTTP/1.1, headers can be inspected by tools like Wireshark
- In HTTP/2, headers are compressed, thus saves on payload size and harder to inspect/debug

# HTTP Response Structure has 5 parts:
Protocol version: HTTP/1.1
Status code: 200 / 400 etc
Status message: OK
HTTP Headers: Content-Length, Content-Type, etc
Message Body

- Status code
1xx = informational response
2xx = success
3xx = Redirection
4xx = Client Errors
5xx = Server Errors

























